{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1)  What is Logistic Regression, and how does it differ from Linear\n",
        "Regression?\n",
        "Ans. Logistic Regression is a statistical method used primarily for binary classification tasks, where the goal is to predict the probability of an outcome belonging to one of two categories—such as spam vs. not spam or disease vs. no disease. It works by applying a logistic (sigmoid) function to a linear combination of input features, which transforms the output into a probability value between 0 and 1. In contrast, Linear Regression is used for predicting continuous numerical values, like house prices or temperature, based on input variables. It models the relationship between the dependent and independent variables using a straight-line equation and can produce any real number as output. The key difference lies in their output and application: Linear Regression predicts quantities, while Logistic Regression predicts probabilities for classification. Additionally, Logistic Regression uses a log loss (cross-entropy) as its cost function, whereas Linear Regression uses mean squared error.\n",
        "\n",
        "2) Explain the role of the Sigmoid function in Logistic Regression.\n",
        "Ans The sigmoid function in logistic regression transforms linear outputs into probabilities between 0 and 1, enabling binary classification. It ensures that predictions are interpretable as likelihoods of belonging to a specific class\n",
        "\n",
        "3) What is Regularization in Logistic Regression and why is it needed?\n",
        "Ans Regularization in logistic regression is a technique used to prevent overfitting by adding a penalty to the model’s complexity. It helps ensure that the model generalizes well to unseen data rather than memorizing the training set.\n",
        "\n",
        "4) What are some common evaluation metrics for classification models, and why are they important?\n",
        "Ans. Common evaluation metrics for classification models include accuracy, precision, recall, F1-score, ROC-AUC, and confusion matrix. These metrics are essential for understanding how well a model performs, especially in real-world scenarios with imbalanced data or varying costs of misclassification\n"
      ],
      "metadata": {
        "id": "GfLCRWPotkR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#5)  Write a Python program that loads a CSV file into a Pandas DataFrame,\n",
        "#splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "#(Use Dataset from sklearn package)\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load dataset from sklearn\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Step 2: Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(X, columns=iris.feature_names)\n",
        "df['target'] = y\n",
        "\n",
        "# Step 3: Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop('target', axis=1),\n",
        "    df['target'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Step 4: Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Predict and calculate accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Logistic Regression Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNK1kiK6whLs",
        "outputId": "5383851d-8cd0-4d8f-d8d7-9f8aac6bbfe3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6)  Write a Python program to train a Logistic Regression model using L2\n",
        "#regularization (Ridge) and print the model coefficients and accuracy. (Use Dataset from sklearn package)\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load dataset from sklearn\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Step 2: Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(X, columns=iris.feature_names)\n",
        "df['target'] = y\n",
        "\n",
        "# Step 3: Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop('target', axis=1),\n",
        "    df['target'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Step 4: Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Predict and calculate accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Logistic Regression Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz5RTTEqxLg8",
        "outputId": "aec17728-8b5b-4b11-e929-cdbcbf453a8e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7)  Write a Python program to train a Logistic Regression model for multiclass\n",
        "#classification using multi_class='ovr' and print the classification report. (Use Dataset from sklearn package)\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Step 1: Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Step 2: Convert to DataFrame (optional, for clarity)\n",
        "df = pd.DataFrame(X, columns=iris.feature_names)\n",
        "df['target'] = y\n",
        "\n",
        "# Step 3: Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop('target', axis=1),\n",
        "    df['target'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Step 4: Train Logistic Regression with One-vs-Rest strategy\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Predict and print classification report\n",
        "y_pred = model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred, target_names=iris.target_names)\n",
        "print(\"Classification Report:\\n\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fki6RpQdxmQO",
        "outputId": "04354433-3f79-467a-b610-c24ab51edf40"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8)  Write a Python program to apply GridSearchCV to tune C and penalty\n",
        "#hyperparameters for Logistic Regression and print the best parameters and validation\n",
        "#accuracy.\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Step 2: Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Define parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']  # 'liblinear' supports both l1 and l2\n",
        "}\n",
        "\n",
        "# Step 4: Apply GridSearchCV\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=200), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Print best parameters and validation accuracy\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(f\"Best Cross-Validation Accuracy: {grid.best_score_:.2f}\")\n",
        "\n",
        "# Step 6: Evaluate on test set\n",
        "y_pred = grid.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Set Accuracy: {test_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9p3jjxHx4hw",
        "outputId": "128c651f-7ab1-4629-ba2c-b9dd773744a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best Cross-Validation Accuracy: 0.97\n",
            "Test Set Accuracy: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#9): Write a Python program to standardize the features before training Logistic\n",
        "#Regression and compare the model's accuracy with and without scaling.\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Step 2: Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Train Logistic Regression WITHOUT scaling\n",
        "model_no_scaling = LogisticRegression(max_iter=200)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "# Step 4: Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 5: Train Logistic Regression WITH scaling\n",
        "model_scaled = LogisticRegression(max_iter=200)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Step 6: Compare results\n",
        "print(f\"Accuracy without scaling: {accuracy_no_scaling:.2f}\")\n",
        "print(f\"Accuracy with scaling:    {accuracy_scaled:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liLjWh9Jx4_v",
        "outputId": "08ea5a4e-5094-4bb7-95fc-b83aefca4f2d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.96\n",
            "Accuracy with scaling:    0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10) Imagine you are working at an e-commerce company that wants to predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you’d take to build a Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business\n",
        "use case.\n",
        "Ans. To build a robust Logistic Regression model for predicting customer response in an imbalanced e-commerce dataset (5% responders), here's a step-by-step approach:\n",
        " 1. Data Handling & Preprocessing\n",
        " 2. Addressing Class Imbalance\n",
        " 3. Feature Scaling\n",
        " 4. Hyperparameter Tuning\n",
        " 5. Model Evaluation\n"
      ],
      "metadata": {
        "id": "iMqYUSpQzFTe"
      }
    }
  ]
}